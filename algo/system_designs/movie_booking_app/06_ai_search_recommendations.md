# AI-Powered Search & Recommendation Engine

## Overview

This document covers the AI/ML-powered search and recommendation system for the movie booking platform, including natural language search, semantic understanding, and personalized recommendations.

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AI SEARCH & RECOMMENDATION SYSTEM                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  User Query: "Show me action movies like John Wick tonight"    â”‚
â”‚       â†“                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Search Service                                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚  â”‚
â”‚  â”‚  â”‚ Traditional    â”‚  â”‚ AI-Powered     â”‚                 â”‚  â”‚
â”‚  â”‚  â”‚ Search         â”‚  â”‚ Search (NLP)   â”‚                 â”‚  â”‚
â”‚  â”‚  â”‚                â”‚  â”‚                â”‚                 â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Elasticsearchâ”‚  â”‚ â€¢ Semantic     â”‚                 â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Keyword matchâ”‚  â”‚   understandingâ”‚                 â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Filters      â”‚  â”‚ â€¢ Entity       â”‚                 â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Autocomplete â”‚  â”‚   extraction   â”‚                 â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â€¢ Intent       â”‚                 â”‚  â”‚
â”‚  â”‚                      â”‚   recognition  â”‚                 â”‚  â”‚
â”‚  â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â†“                         â†“                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Recommendation Engine                                    â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚  â”‚
â”‚  â”‚  â”‚ Collaborative   â”‚  â”‚ Content-Based   â”‚              â”‚  â”‚
â”‚  â”‚  â”‚ Filtering       â”‚  â”‚ Filtering       â”‚              â”‚  â”‚
â”‚  â”‚  â”‚                 â”‚  â”‚                 â”‚              â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ User-User     â”‚  â”‚ â€¢ Movie metadataâ”‚              â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Item-Item     â”‚  â”‚ â€¢ Genre, cast   â”‚              â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Matrix Factor â”‚  â”‚ â€¢ Plot keywords â”‚              â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â”‚
â”‚  â”‚           â†“                    â†“                         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚  â”‚
â”‚  â”‚  â”‚ Hybrid Recommendation Model              â”‚           â”‚  â”‚
â”‚  â”‚  â”‚ (Neural Collaborative Filtering)         â”‚           â”‚  â”‚
â”‚  â”‚  â”‚                                           â”‚           â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Deep learning model                     â”‚           â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ User embeddings (256D)                 â”‚           â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Movie embeddings (256D)                â”‚           â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Context features                        â”‚           â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â†“                                                         â”‚
â”‚  Personalized Results + Ranking                                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component 1: AI-Powered Search

### 1.1 Natural Language Understanding

**User Query Examples:**
```
âŒ Traditional search struggles with:
  â€¢ "Show me something like Inception"
  â€¢ "Action movies similar to John Wick tonight"
  â€¢ "Funny movies for kids near downtown"

âœ… AI-powered search understands:
  â€¢ Intent: search, filter, recommendation
  â€¢ Entities: genre, movie name, location, time
  â€¢ Similarity: "like", "similar to"
  â€¢ Context: "tonight", "near me", "for kids"
```

### 1.2 Implementation

**Architecture:**
```python
# Pseudocode for AI Search Pipeline

def ai_powered_search(query, user_context):
    # Step 1: Query understanding with NLP
    intent, entities = extract_intent_entities(query)
    # Uses: spaCy or transformer model (BERT)

    # Step 2: Semantic search
    query_embedding = encode_query(query)              # 768D vector
    similar_movies = vector_db.search(query_embedding, top_k=100)

    # Step 3: Apply extracted filters
    filtered = apply_filters(similar_movies, entities)

    # Step 4: Personalized ranking
    ranked = recommendation_model.rerank(
        movies=filtered,
        user_id=user_context.user_id,
        context=user_context
    )

    # Step 5: Return top results
    return ranked[:10]
```

**NLP Pipeline:**
```
User Query: "Show me action movies like John Wick tonight"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: Intent Classification                          â”‚
â”‚   Model: BERT fine-tuned on movie queries             â”‚
â”‚   Output: Intent = "search_similar"                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: Entity Extraction (NER)                        â”‚
â”‚   Model: spaCy or custom NER                           â”‚
â”‚   Output:                                               â”‚
â”‚     - Genre: "action"                                   â”‚
â”‚     - Reference Movie: "John Wick"                     â”‚
â”‚     - Time: "tonight"                                   â”‚
â”‚     - Location: user's current location                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: Query Expansion                                 â”‚
â”‚   Expand "John Wick" to similar movies:                â”‚
â”‚     - Keanu Reeves films                               â”‚
â”‚     - Gun-fu action movies                             â”‚
â”‚     - Neo-noir thrillers                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: Semantic Search                                 â”‚
â”‚   Vector DB query with combined constraints             â”‚
â”‚   Returns: Top 100 candidate movies                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5: Personalized Reranking                         â”‚
â”‚   ML model considers user history                       â”‚
â”‚   Final output: Top 10 personalized results            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 Technical Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NLP Models:                                         â”‚
â”‚    â€¢ Query Understanding: BERT / RoBERTa             â”‚
â”‚    â€¢ Entity Extraction: spaCy / Custom NER           â”‚
â”‚    â€¢ Semantic Encoding: Sentence-BERT                â”‚
â”‚                                                      â”‚
â”‚  Vector Database:                                    â”‚
â”‚    â€¢ Pinecone / Weaviate / Milvus                    â”‚
â”‚    â€¢ Movie embeddings: 768D                          â”‚
â”‚    â€¢ Fast ANN search (<50ms)                         â”‚
â”‚                                                      â”‚
â”‚  Traditional Search:                                 â”‚
â”‚    â€¢ Elasticsearch for keyword matching              â”‚
â”‚    â€¢ BM25 scoring                                    â”‚
â”‚    â€¢ Filters, facets, aggregations                   â”‚
â”‚                                                      â”‚
â”‚  Hybrid Approach:                                    â”‚
â”‚    â€¢ Combine semantic + keyword scores               â”‚
â”‚    â€¢ Score = 0.6 * semantic + 0.4 * keyword          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component 2: Recommendation Engine

### 2.1 Multiple Recommendation Strategies

**1. Collaborative Filtering (User-Based)**
```
Concept: "Users similar to you also liked..."

Algorithm: Matrix Factorization (SVD)
  â€¢ User-Movie rating matrix: R (sparse)
  â€¢ Factorize: R â‰ˆ U Ã— V^T
  â€¢ U: user embeddings (100K users Ã— 128D)
  â€¢ V: movie embeddings (5K movies Ã— 128D)

Prediction:
  rating(user_i, movie_j) = U[i] Â· V[j]

Pros: Discovers hidden patterns, serendipity
Cons: Cold start problem for new users
```

**2. Content-Based Filtering**
```
Concept: "You liked X, here's similar Y"

Features per movie:
  â€¢ Genre: [action, thriller, drama]
  â€¢ Cast: [actor1, actor2, ...]
  â€¢ Director: name
  â€¢ Keywords: [revenge, assassin, gun-fu, ...]
  â€¢ Plot embedding: 768D vector from BERT

Similarity:
  sim(movie_i, movie_j) = cosine(features_i, features_j)

Pros: No cold start, explainable
Cons: Limited diversity, filter bubble
```

**3. Neural Collaborative Filtering (NCF)**
```
Deep Learning Approach (BEST!)

Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input Layer                                      â”‚
â”‚    â€¢ user_id â†’ Embedding(100K, 256)              â”‚
â”‚    â€¢ movie_id â†’ Embedding(5K, 256)               â”‚
â”‚    â€¢ context features (time, device, ...)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hidden Layers                                    â”‚
â”‚    â€¢ Dense(512, ReLU)                             â”‚
â”‚    â€¢ BatchNorm + Dropout(0.3)                     â”‚
â”‚    â€¢ Dense(256, ReLU)                             â”‚
â”‚    â€¢ BatchNorm + Dropout(0.3)                     â”‚
â”‚    â€¢ Dense(128, ReLU)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output Layer                                     â”‚
â”‚    â€¢ Dense(1, Sigmoid)                            â”‚
â”‚    â€¢ Predicted rating: [0, 1]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Training:
  â€¢ Loss: Binary Cross-Entropy (implicit feedback)
  â€¢ Optimizer: Adam
  â€¢ Batch size: 1024
  â€¢ Negative sampling: 4 negatives per positive

Performance:
  â€¢ Training: 1M examples/sec on V100 GPU
  â€¢ Inference: <5ms per user
```

### 2.2 Two-Stage Recommendation Pipeline

**Why Two-Stage?**
- Can't run expensive model on entire catalog (5K movies)
- Need fast candidate generation + precise ranking

```
Stage 1: CANDIDATE GENERATION (Fast, Broad)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Goal: Reduce 5K movies â†’ Top 100 candidates
Method: Vector similarity search (ANN)
Latency: <50ms

user_embedding = get_user_embedding(user_id)         # 256D
candidates = vector_db.search(
    query=user_embedding,
    top_k=100,
    filters={"in_theaters": True, "city": user_city}
)

Cost: Cheap (CPU-based ANN)
Recall@100: ~95% (covers most relevant movies)


Stage 2: PRECISE RANKING (Slower, Accurate)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Goal: Rank top 100 â†’ Final top 10
Method: Neural network with rich features
Latency: <100ms

for movie in candidates:
    features = extract_features(user, movie, context)
    score = ncf_model.predict(features)

top_10 = sort(candidates, by=score, descending=True)[:10]

Cost: Moderate (GPU inference)
NDCG@10: 0.85 (very accurate ranking)


Total Latency: 50ms + 100ms = 150ms âœ…
```

### 2.3 Cold Start Problem Solutions

**Problem:** New user with no history

**Solutions:**

**1. Popularity-Based Fallback**
```python
if user.num_ratings == 0:
    return top_movies_by_popularity(user.location)
```

**2. Demographic Signals**
```python
if user.age and user.gender:
    similar_users = find_users_by_demographics(user.age, user.gender)
    return collaborative_filter(similar_users)
```

**3. Quick Onboarding Quiz**
```
"Help us personalize your experience!"
  â€¢ Select your favorite genres: [Action, Comedy, Drama, ...]
  â€¢ Rate these popular movies: [Avengers, Inception, ...]

After 3-5 ratings â†’ cold start solved!
```

**4. Content-Based (No History Needed)**
```python
# User selected genre: "Action"
return content_based_filter(
    genre="action",
    sort_by="popularity",
    limit=10
)
```

### 2.4 Real-Time vs Batch Recommendations

**Batch Recommendations (Offline)**
```
Frequency: Daily (every night at 2 AM)
Process:
  1. Train collaborative filtering on all historical data
  2. Generate top-50 recommendations for ALL users
  3. Store in Redis: user_id â†’ [movie1, movie2, ...]

Pros:
  â€¢ Fast serving (<1ms, just cache lookup)
  â€¢ Can use expensive models
  â€¢ Consistent results

Cons:
  â€¢ Stale (up to 24 hours old)
  â€¢ Doesn't adapt to recent actions

Use case: Homepage recommendations
```

**Real-Time Recommendations (Online)**
```
Trigger: Every user action (click, search, booking)
Process:
  1. Fetch user's recent actions (last 1 hour)
  2. Update user embedding in real-time
  3. Re-rank batch recommendations with new signal

Latency: <100ms

Pros:
  â€¢ Fresh, adapts immediately
  â€¢ Captures trending content

Cons:
  â€¢ Higher compute cost
  â€¢ More complex infrastructure

Use case: "Because you just booked...", trending movies
```

**Hybrid Approach (BEST!):**
```python
def get_recommendations(user_id):
    # Get batch recommendations (cached)
    batch_recs = redis.get(f"recs:batch:{user_id}")     # Fast!

    # Get real-time signals (fresh)
    recent_actions = get_recent_actions(user_id, hours=1)

    if recent_actions:
        # Re-rank with real-time signal
        scores = model.predict_batch(
            movies=batch_recs,
            user_embedding=get_user_embedding(user_id),
            recent_actions=recent_actions
        )
        return rerank(batch_recs, scores)
    else:
        # Just return batch recs
        return batch_recs
```

### 2.5 Diversity & Exploration

**Problem:** Recommendations too similar (filter bubble)

**Solution: Diversification Strategies**

**1. Genre Diversity**
```python
# Ensure at least 3 different genres in top-10
top_10 = []
genres_seen = set()

for movie in ranked_movies:
    if len(genres_seen) < 3 or movie.genre in genres_seen:
        top_10.append(movie)
        genres_seen.add(movie.genre)
    if len(top_10) == 10:
        break
```

**2. Exploration vs Exploitation (Îµ-greedy)**
```python
epsilon = 0.2  # 20% exploration

if random() < epsilon:
    # EXPLORE: Show unexpected/new movies
    return sample_random_popular_movies(n=10)
else:
    # EXPLOIT: Show personalized recommendations
    return ncf_model.recommend(user_id, n=10)
```

**3. Thompson Sampling (MAB)**
```python
# Multi-armed bandit for A/B testing recommendations

for movie in candidates:
    # Sample from posterior distribution
    estimated_ctr = beta_distribution(
        alpha=movie.clicks + 1,
        beta=movie.impressions - movie.clicks + 1
    ).sample()

# Show movies with highest sampled CTR
```

---

## Feature Engineering

### User Features
```python
user_features = {
    # Demographic
    "age": user.age,
    "gender": user.gender,
    "location_city": user.city,

    # Behavioral
    "total_bookings": user.booking_count,
    "avg_rating": user.avg_rating,
    "favorite_genres": user.top_3_genres,
    "booking_frequency": bookings_per_month,

    # Temporal
    "preferred_day": most_common_booking_day,
    "preferred_time": most_common_booking_time,

    # Embedding
    "user_embedding": user_embedding_256d,  # From NCF model
}
```

### Movie Features
```python
movie_features = {
    # Metadata
    "title": movie.title,
    "genres": movie.genres,
    "cast": movie.cast[:5],  # Top 5 actors
    "director": movie.director,
    "release_year": movie.year,
    "runtime_minutes": movie.runtime,

    # Popularity
    "imdb_rating": movie.imdb_rating,
    "rt_score": movie.rotten_tomatoes,
    "total_bookings": movie.booking_count,
    "trending_score": bookings_last_7_days,

    # Content
    "plot_summary": movie.plot,
    "keywords": movie.keywords,  # ["revenge", "assassin", ...]

    # Embedding
    "movie_embedding": movie_embedding_256d,  # From NCF model
    "plot_embedding": bert_encode(movie.plot),  # 768D
}
```

### Context Features
```python
context_features = {
    # Temporal
    "day_of_week": current_day,  # Mon-Sun
    "time_of_day": current_hour,  # 0-23
    "is_weekend": is_weekend,
    "is_holiday": is_holiday,

    # Session
    "session_duration": minutes_on_site,
    "pages_viewed": page_count,
    "searches_made": search_count,

    # Device
    "device_type": "mobile" | "desktop",
    "browser": user.browser,
}
```

---

## Evaluation Metrics

### Offline Metrics (Model Training)
```
Ranking Metrics:
  â€¢ Precision@K: What % of top-K are relevant?
    P@10 = (# relevant in top-10) / 10
    Target: >0.6

  â€¢ Recall@K: What % of relevant items in top-K?
    R@10 = (# relevant in top-10) / (total relevant)
    Target: >0.4

  â€¢ NDCG@K: Normalized Discounted Cumulative Gain
    Considers position (top results weighted more)
    Target: >0.75

  â€¢ Hit Rate@K: Did user interact with ANY in top-K?
    Target: >0.8

Classification Metrics (Implicit Feedback):
  â€¢ AUC-ROC: 0.82 (target: >0.80)
  â€¢ Log Loss: 0.34 (target: <0.4)
```

### Online Metrics (A/B Testing)
```
User Engagement:
  â€¢ Click-Through Rate (CTR): 6.2% (baseline: 5%)
  â€¢ Conversion Rate: 18% (clicked â†’ booked)
  â€¢ Time to booking: 4.2 min (faster is better)

Business Metrics:
  â€¢ Bookings per user: 2.1 (baseline: 1.8)
  â€¢ Revenue per user: $42 (baseline: $36)
  â€¢ User retention: 78% return within 30 days

Quality Metrics:
  â€¢ Diversity score: 0.72 (how diverse are recs?)
  â€¢ Coverage: 85% (% of catalog recommended)
  â€¢ Novelty: 0.65 (how unexpected are recs?)
```

---

## Interview Questions & Answers

**Q1: How do you handle the cold start problem?**
```
Multi-pronged approach:
1. New users: Popularity-based + quick onboarding quiz
2. New movies: Content-based (metadata, plot similarity)
3. Fallback chain:
   - Try personalized (if >10 ratings)
   - Try demographic-based (if <10 ratings)
   - Use popularity (if new user)
```

**Q2: Explain your two-stage ranking system.**
```
Stage 1: Candidate Generation (ANN search)
  â€¢ Input: User embedding (256D)
  â€¢ Output: Top 100 candidates
  â€¢ Latency: <50ms
  â€¢ Recall@100: 95%

Stage 2: Precise Ranking (Neural network)
  â€¢ Input: Rich features (user + movie + context)
  â€¢ Output: Top 10 recommendations
  â€¢ Latency: <100ms
  â€¢ NDCG@10: 0.85

Why? Can't afford to run expensive model on 5K movies.
Two-stage balances speed + accuracy.
```

**Q3: How do you ensure recommendation diversity?**
```
1. Genre diversity: Force 3+ genres in top-10
2. Exploration (Îµ-greedy): 20% random popular movies
3. MMR (Maximal Marginal Relevance):
   - Balance relevance + dissimilarity
4. Position-aware: Don't cluster similar items together
```

**Q4: Real-time vs batch recommendations?**
```
Hybrid approach:
- Batch (daily): Generate top-50 for all users (cached)
- Real-time: Re-rank based on recent actions
- Cost-effective + fresh results
- Latency: <100ms (cache lookup + reranking)
```

**Q5: How do you measure success?**
```
Offline: NDCG@10, Precision@10, AUC
Online: CTR (+1.2%), Conversion (+15%), Revenue (+17%)
A/B test: 2 weeks, 10K users per variant
```

---

## Implementation Checklist

- [x] Vector database setup (Pinecone/Milvus)
- [x] Movie embedding generation (BERT)
- [x] NCF model training pipeline
- [x] Two-stage ranking system
- [x] Cold start handling
- [x] Real-time feature computation
- [x] A/B testing framework
- [x] Offline evaluation metrics
- [x] Online monitoring dashboard
- [x] Model retraining automation

---

**Time to implement: 4-6 weeks**
**Team size: 2-3 ML engineers + 1 backend engineer**
**Complexity: High**
**Impact: +15-20% booking conversion** ğŸš€
